{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.104317Z",
     "start_time": "2024-05-04T22:13:27.100755Z"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image_h = 8\n",
    "image_w = 8\n",
    "image_size = image_h * image_w\n",
    "print_every = 100\n",
    "\n",
    "\n",
    "device = '/CPU:0'"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.182600Z",
     "start_time": "2024-05-04T22:13:27.169078Z"
    }
   },
   "source": [
    "def load_dataset(test_proportion=0.2, val_proportion=0.2, flatten=True):\n",
    "    digits = load_digits()\n",
    "    digits_data = digits.data if flatten else digits.data.reshape(digits.data.shape[0], 8, 8, 1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(digits_data, digits.target, test_size=val_proportion, random_state=1337)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_proportion / (1 - val_proportion), random_state=1337)\n",
    "\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=False)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1077, 8, 8, 1)\n",
      "Train labels shape:  (1077,) int64\n",
      "Validation data shape:  (360, 8, 8, 1)\n",
      "Validation labels shape:  (360,)\n",
      "Test data shape:  (360, 8, 8, 1)\n",
      "Test labels shape:  (360,)\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.187925Z",
     "start_time": "2024-05-04T22:13:27.183787Z"
    }
   },
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.207103Z",
     "start_time": "2024-05-04T22:13:27.188594Z"
    }
   },
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 8, 8, 1) (64,)\n",
      "1 (64, 8, 8, 1) (64,)\n",
      "2 (64, 8, 8, 1) (64,)\n",
      "3 (64, 8, 8, 1) (64,)\n",
      "4 (64, 8, 8, 1) (64,)\n",
      "5 (64, 8, 8, 1) (64,)\n",
      "6 (64, 8, 8, 1) (64,)\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.241412Z",
     "start_time": "2024-05-04T22:13:27.208352Z"
    }
   },
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU \n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU \n",
    "5. Полносвязный слой \n",
    "6. Функция активации Softmax \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.246570Z",
     "start_time": "2024-05-04T22:13:27.242308Z"
    }
   },
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), activation='relu', padding='same',\n",
    "                                            kernel_initializer=initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), activation='relu', padding='same',\n",
    "                                            kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu',\n",
    "                                         kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                         kernel_initializer=initializer)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        scores = self.fc2(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.310155Z",
     "start_time": "2024-05-04T22:13:27.247507Z"
    }
   },
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 1, 8, 8))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.317578Z",
     "start_time": "2024-05-04T22:13:27.312327Z"
    }
   },
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False, print_every = 1, loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            # train_loss.reset_states()\n",
    "            # train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        # val_loss.reset_states()\n",
    "                        # val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1\n",
    "        return train_accuracy.result()*100"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:27.918769Z",
     "start_time": "2024-05-04T22:13:27.318620Z"
    }
   },
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 8.162327766418457, Accuracy: 12.5, Val Loss: 13.33396053314209, Val Accuracy: 44.72222137451172\n",
      "Iteration 1, Epoch 1, Loss: 10.469593048095703, Accuracy: 29.6875, Val Loss: 15.84652328491211, Val Accuracy: 41.80555725097656\n",
      "Iteration 2, Epoch 1, Loss: 14.974430084228516, Accuracy: 28.64583396911621, Val Loss: 17.982723236083984, Val Accuracy: 43.98147964477539\n",
      "Iteration 3, Epoch 1, Loss: 17.286230087280273, Accuracy: 34.765625, Val Loss: 15.2111234664917, Val Accuracy: 48.125\n",
      "Iteration 4, Epoch 1, Loss: 15.572816848754883, Accuracy: 39.375, Val Loss: 13.973977088928223, Val Accuracy: 53.0555534362793\n",
      "Iteration 5, Epoch 1, Loss: 13.992852210998535, Accuracy: 45.833335876464844, Val Loss: 12.330374717712402, Val Accuracy: 56.89814758300781\n",
      "Iteration 6, Epoch 1, Loss: 12.350545883178711, Accuracy: 51.33928680419922, Val Loss: 10.861659049987793, Val Accuracy: 60.357139587402344\n",
      "Iteration 7, Epoch 1, Loss: 11.193564414978027, Accuracy: 54.4921875, Val Loss: 9.66036319732666, Val Accuracy: 63.784725189208984\n",
      "Iteration 8, Epoch 1, Loss: 10.239896774291992, Accuracy: 57.8125, Val Loss: 8.74028205871582, Val Accuracy: 66.45062255859375\n",
      "Iteration 9, Epoch 1, Loss: 9.421507835388184, Accuracy: 61.25, Val Loss: 8.006183624267578, Val Accuracy: 68.75\n",
      "Iteration 10, Epoch 1, Loss: 8.631328582763672, Accuracy: 64.20454406738281, Val Loss: 7.357880115509033, Val Accuracy: 70.88384246826172\n",
      "Iteration 11, Epoch 1, Loss: 8.046708106994629, Accuracy: 66.27604675292969, Val Loss: 6.899457931518555, Val Accuracy: 71.99073791503906\n",
      "Iteration 12, Epoch 1, Loss: 7.730740547180176, Accuracy: 66.70672607421875, Val Loss: 6.672813892364502, Val Accuracy: 72.45726776123047\n",
      "Iteration 13, Epoch 1, Loss: 7.44323205947876, Accuracy: 67.74553680419922, Val Loss: 6.243589878082275, Val Accuracy: 73.86904907226562\n",
      "Iteration 14, Epoch 1, Loss: 7.092992782592773, Accuracy: 69.0625, Val Loss: 5.892197132110596, Val Accuracy: 75.05555725097656\n",
      "Iteration 15, Epoch 1, Loss: 6.724445343017578, Accuracy: 70.21484375, Val Loss: 5.576389789581299, Val Accuracy: 76.07638549804688\n",
      "Iteration 16, Epoch 1, Loss: 6.391616344451904, Accuracy: 71.40204620361328, Val Loss: 5.272624969482422, Val Accuracy: 77.18954467773438\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:28.824273Z",
     "start_time": "2024-05-04T22:13:27.919506Z"
    }
   },
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, print_every=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 9.984516143798828, Accuracy: 10.9375, Val Loss: 11.171607971191406, Val Accuracy: 15.555556297302246\n",
      "Iteration 1, Epoch 1, Loss: 9.524357795715332, Accuracy: 17.1875, Val Loss: 8.430203437805176, Val Accuracy: 27.5\n",
      "Iteration 2, Epoch 1, Loss: 8.767992973327637, Accuracy: 19.270832061767578, Val Loss: 6.809556007385254, Val Accuracy: 34.53703689575195\n",
      "Iteration 3, Epoch 1, Loss: 7.636340141296387, Accuracy: 25.78125, Val Loss: 5.730673313140869, Val Accuracy: 38.33333206176758\n",
      "Iteration 4, Epoch 1, Loss: 6.5225629806518555, Accuracy: 31.562501907348633, Val Loss: 4.974728107452393, Val Accuracy: 41.0555534362793\n",
      "Iteration 5, Epoch 1, Loss: 5.69639778137207, Accuracy: 35.9375, Val Loss: 4.413943290710449, Val Accuracy: 43.61111068725586\n",
      "Iteration 6, Epoch 1, Loss: 5.062277793884277, Accuracy: 38.83928680419922, Val Loss: 3.9844436645507812, Val Accuracy: 46.5476188659668\n",
      "Iteration 7, Epoch 1, Loss: 4.6079230308532715, Accuracy: 41.6015625, Val Loss: 3.6449267864227295, Val Accuracy: 49.09722137451172\n",
      "Iteration 8, Epoch 1, Loss: 4.248562335968018, Accuracy: 43.229164123535156, Val Loss: 3.367664098739624, Val Accuracy: 51.41975402832031\n",
      "Iteration 9, Epoch 1, Loss: 3.950854778289795, Accuracy: 45.625, Val Loss: 3.136014699935913, Val Accuracy: 53.38888931274414\n",
      "Iteration 10, Epoch 1, Loss: 3.6703414916992188, Accuracy: 48.72159194946289, Val Loss: 2.9396724700927734, Val Accuracy: 55.227272033691406\n",
      "Iteration 11, Epoch 1, Loss: 3.4482078552246094, Accuracy: 51.04166793823242, Val Loss: 2.7696781158447266, Val Accuracy: 56.94444274902344\n",
      "Iteration 12, Epoch 1, Loss: 3.2519469261169434, Accuracy: 52.40384292602539, Val Loss: 2.6201045513153076, Val Accuracy: 58.589744567871094\n",
      "Iteration 13, Epoch 1, Loss: 3.0750186443328857, Accuracy: 53.90625, Val Loss: 2.486912250518799, Val Accuracy: 60.138885498046875\n",
      "Iteration 14, Epoch 1, Loss: 2.9212160110473633, Accuracy: 55.52083206176758, Val Loss: 2.3673572540283203, Val Accuracy: 61.46296310424805\n",
      "Iteration 15, Epoch 1, Loss: 2.7760698795318604, Accuracy: 56.73828125, Val Loss: 2.2584450244903564, Val Accuracy: 62.829864501953125\n",
      "Iteration 16, Epoch 1, Loss: 2.645021438598633, Accuracy: 58.12441635131836, Val Loss: 2.1580824851989746, Val Accuracy: 64.26470947265625\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:29.393848Z",
     "start_time": "2024-05-04T22:13:28.825131Z"
    }
   },
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8, 8, 1)\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 8.52289867401123, Accuracy: 12.5, Val Loss: 12.101468086242676, Val Accuracy: 41.666664123535156\n",
      "Iteration 1, Epoch 1, Loss: 9.541996002197266, Accuracy: 29.6875, Val Loss: 9.708847999572754, Val Accuracy: 48.33333206176758\n",
      "Iteration 2, Epoch 1, Loss: 9.516554832458496, Accuracy: 36.458335876464844, Val Loss: 10.252432823181152, Val Accuracy: 47.22222137451172\n",
      "Iteration 3, Epoch 1, Loss: 9.351118087768555, Accuracy: 39.453125, Val Loss: 9.531935691833496, Val Accuracy: 52.361114501953125\n",
      "Iteration 4, Epoch 1, Loss: 9.292335510253906, Accuracy: 45.9375, Val Loss: 8.295585632324219, Val Accuracy: 56.722225189208984\n",
      "Iteration 5, Epoch 1, Loss: 8.164918899536133, Accuracy: 52.08333206176758, Val Loss: 7.129280090332031, Val Accuracy: 61.6203727722168\n",
      "Iteration 6, Epoch 1, Loss: 7.2055511474609375, Accuracy: 57.142860412597656, Val Loss: 6.501587867736816, Val Accuracy: 64.04761505126953\n",
      "Iteration 7, Epoch 1, Loss: 6.7384772300720215, Accuracy: 58.984375, Val Loss: 6.208334445953369, Val Accuracy: 65.20833587646484\n",
      "Iteration 8, Epoch 1, Loss: 6.570481777191162, Accuracy: 60.59027862548828, Val Loss: 6.0510783195495605, Val Accuracy: 66.97531127929688\n",
      "Iteration 9, Epoch 1, Loss: 6.316821098327637, Accuracy: 63.28125, Val Loss: 5.707818031311035, Val Accuracy: 68.19444274902344\n",
      "Iteration 10, Epoch 1, Loss: 5.820196628570557, Accuracy: 65.90909576416016, Val Loss: 5.299219131469727, Val Accuracy: 70.1515121459961\n",
      "Iteration 11, Epoch 1, Loss: 5.468633651733398, Accuracy: 67.578125, Val Loss: 5.008887767791748, Val Accuracy: 71.22685241699219\n",
      "Iteration 12, Epoch 1, Loss: 5.34352970123291, Accuracy: 68.87019348144531, Val Loss: 4.717066287994385, Val Accuracy: 72.39315795898438\n",
      "Iteration 13, Epoch 1, Loss: 5.019572734832764, Accuracy: 69.75446319580078, Val Loss: 4.425565242767334, Val Accuracy: 73.75\n",
      "Iteration 14, Epoch 1, Loss: 4.75279426574707, Accuracy: 70.9375, Val Loss: 4.232696056365967, Val Accuracy: 74.62963104248047\n",
      "Iteration 15, Epoch 1, Loss: 4.554637908935547, Accuracy: 71.97265625, Val Loss: 4.021700859069824, Val Accuracy: 75.6076431274414\n",
      "Iteration 16, Epoch 1, Loss: 4.3406758308410645, Accuracy: 72.98049926757812, Val Loss: 3.826998472213745, Val Accuracy: 76.53594970703125\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:29.784306Z",
     "start_time": "2024-05-04T22:13:29.394866Z"
    }
   },
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m17/17\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - loss: 8.3488 - sparse_categorical_accuracy: 0.5798 - val_loss: 0.4033 - val_sparse_categorical_accuracy: 0.9444\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.7116 - sparse_categorical_accuracy: 0.9426 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.788570761680603, 0.9277777671813965]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:30.729694Z",
     "start_time": "2024-05-04T22:13:29.785005Z"
    }
   },
   "source": [
    "learning_rate = 5e-4\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    input_shape = (8, 8, 1)\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(channel_1, (5, 5), activation='relu', padding='same',\n",
    "                               kernel_initializer=initializer, input_shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(channel_2, (3, 3), activation='relu', padding='same',\n",
    "                               kernel_initializer=initializer),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=initializer)\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 10.722034454345703, Accuracy: 3.125, Val Loss: 7.324424743652344, Val Accuracy: 5.277777671813965\n",
      "Iteration 1, Epoch 1, Loss: 8.789379119873047, Accuracy: 6.25, Val Loss: 6.39747953414917, Val Accuracy: 6.94444465637207\n",
      "Iteration 2, Epoch 1, Loss: 7.90103006362915, Accuracy: 5.2083330154418945, Val Loss: 5.743509292602539, Val Accuracy: 9.44444465637207\n",
      "Iteration 3, Epoch 1, Loss: 7.133281230926514, Accuracy: 8.203125, Val Loss: 5.200233459472656, Val Accuracy: 12.222222328186035\n",
      "Iteration 4, Epoch 1, Loss: 6.480158805847168, Accuracy: 9.0625, Val Loss: 4.7447285652160645, Val Accuracy: 15.5\n",
      "Iteration 5, Epoch 1, Loss: 5.975378036499023, Accuracy: 11.71875, Val Loss: 4.357387065887451, Val Accuracy: 19.074073791503906\n",
      "Iteration 6, Epoch 1, Loss: 5.472195625305176, Accuracy: 15.848215103149414, Val Loss: 4.0269856452941895, Val Accuracy: 22.619047164916992\n",
      "Iteration 7, Epoch 1, Loss: 5.067516803741455, Accuracy: 20.703125, Val Loss: 3.733898401260376, Val Accuracy: 26.07638931274414\n",
      "Iteration 8, Epoch 1, Loss: 4.697474956512451, Accuracy: 24.30555534362793, Val Loss: 3.476578950881958, Val Accuracy: 29.567899703979492\n",
      "Iteration 9, Epoch 1, Loss: 4.343067646026611, Accuracy: 28.437501907348633, Val Loss: 3.252094030380249, Val Accuracy: 32.72222137451172\n",
      "Iteration 10, Epoch 1, Loss: 4.087741851806641, Accuracy: 31.25, Val Loss: 3.053004264831543, Val Accuracy: 35.909088134765625\n",
      "Iteration 11, Epoch 1, Loss: 3.8403844833374023, Accuracy: 33.984375, Val Loss: 2.876570701599121, Val Accuracy: 38.703704833984375\n",
      "Iteration 12, Epoch 1, Loss: 3.623220920562744, Accuracy: 36.53845977783203, Val Loss: 2.7196106910705566, Val Accuracy: 41.30342102050781\n",
      "Iteration 13, Epoch 1, Loss: 3.440734624862671, Accuracy: 38.72768020629883, Val Loss: 2.5788655281066895, Val Accuracy: 43.67063522338867\n",
      "Iteration 14, Epoch 1, Loss: 3.2702717781066895, Accuracy: 40.9375, Val Loss: 2.4526312351226807, Val Accuracy: 45.96296310424805\n",
      "Iteration 15, Epoch 1, Loss: 3.1213901042938232, Accuracy: 42.87109375, Val Loss: 2.338193655014038, Val Accuracy: 48.14236068725586\n",
      "Iteration 16, Epoch 1, Loss: 2.9756054878234863, Accuracy: 44.28969192504883, Val Loss: 2.234065294265747, Val Accuracy: 50.147056579589844\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:31.238444Z",
     "start_time": "2024-05-04T22:13:30.730887Z"
    }
   },
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m17/17\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.8228 - sparse_categorical_accuracy: 0.4432 - val_loss: 0.3327 - val_sparse_categorical_accuracy: 0.9028\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.3949 - sparse_categorical_accuracy: 0.9081 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4229964315891266, 0.894444465637207]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
    "\n",
    "Ниже представлен пример для полносвязной сети. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:31.254802Z",
     "start_time": "2024-05-04T22:13:31.239825Z"
    }
   },
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:31.810048Z",
     "start_time": "2024-05-04T22:13:31.255536Z"
    }
   },
   "source": [
    "input_shape = (8, 8, 1)\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 11.078691482543945, Accuracy: 3.125, Val Loss: 7.880964279174805, Val Accuracy: 11.666666984558105\n",
      "Iteration 1, Epoch 1, Loss: 9.762127876281738, Accuracy: 8.59375, Val Loss: 6.948307037353516, Val Accuracy: 14.861111640930176\n",
      "Iteration 2, Epoch 1, Loss: 8.673346519470215, Accuracy: 10.9375, Val Loss: 6.2771100997924805, Val Accuracy: 17.685184478759766\n",
      "Iteration 3, Epoch 1, Loss: 7.578333377838135, Accuracy: 14.453125, Val Loss: 5.744487762451172, Val Accuracy: 20.55555534362793\n",
      "Iteration 4, Epoch 1, Loss: 6.7844648361206055, Accuracy: 18.75, Val Loss: 5.301139831542969, Val Accuracy: 24.0\n",
      "Iteration 5, Epoch 1, Loss: 6.20867919921875, Accuracy: 22.395832061767578, Val Loss: 4.924566745758057, Val Accuracy: 26.712963104248047\n",
      "Iteration 6, Epoch 1, Loss: 5.701239109039307, Accuracy: 26.5625, Val Loss: 4.618236064910889, Val Accuracy: 29.4841251373291\n",
      "Iteration 7, Epoch 1, Loss: 5.3088202476501465, Accuracy: 29.8828125, Val Loss: 4.354894161224365, Val Accuracy: 31.77083396911621\n",
      "Iteration 8, Epoch 1, Loss: 5.001967430114746, Accuracy: 32.291664123535156, Val Loss: 4.113784313201904, Val Accuracy: 34.01234436035156\n",
      "Iteration 9, Epoch 1, Loss: 4.726457118988037, Accuracy: 33.75, Val Loss: 3.897637367248535, Val Accuracy: 36.11111068725586\n",
      "Iteration 10, Epoch 1, Loss: 4.482344150543213, Accuracy: 35.79545211791992, Val Loss: 3.709383487701416, Val Accuracy: 38.080806732177734\n",
      "Iteration 11, Epoch 1, Loss: 4.2623820304870605, Accuracy: 37.369789123535156, Val Loss: 3.5429506301879883, Val Accuracy: 39.97685241699219\n",
      "Iteration 12, Epoch 1, Loss: 4.067134380340576, Accuracy: 38.46154022216797, Val Loss: 3.393028497695923, Val Accuracy: 41.70940399169922\n",
      "Iteration 13, Epoch 1, Loss: 3.8685877323150635, Accuracy: 40.06696319580078, Val Loss: 3.2571098804473877, Val Accuracy: 43.31349182128906\n",
      "Iteration 14, Epoch 1, Loss: 3.707324504852295, Accuracy: 42.08333206176758, Val Loss: 3.1359782218933105, Val Accuracy: 44.64815139770508\n",
      "Iteration 15, Epoch 1, Loss: 3.5640928745269775, Accuracy: 43.359375, Val Loss: 3.0216875076293945, Val Accuracy: 46.0069465637207\n",
      "Iteration 16, Epoch 1, Loss: 3.4264256954193115, Accuracy: 44.56824493408203, Val Loss: 2.911500930786133, Val Accuracy: 47.54901885986328\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T22:13:31.935944Z",
     "start_time": "2024-05-04T22:13:31.810871Z"
    }
   },
   "source": [
    "num_epochs = 10\n",
    "\n",
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size, dense_units, dropout_rate, regularizer):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_filters, kernel_size, activation='relu', padding='same', kernel_initializer=initializer, kernel_regularizer=regularizer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_filters, kernel_size, activation='relu', padding='same', kernel_initializer=initializer, kernel_regularizer=regularizer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(dense_units, activation='relu', kernel_initializer=initializer, kernel_regularizer=regularizer)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.fc2 = tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Перебор гиперпараметров\n",
    "num_filters_list = [32, 64]\n",
    "kernel_size_list = [(3, 3), (5, 5)]\n",
    "dense_units_list = [128, 256]\n",
    "dropout_rate_list = [0.3, 0.5]\n",
    "regularizer_list = [None, tf.keras.regularizers.l2(0.001)]\n",
    "loss_list = [\n",
    "    tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    tf.keras.losses.CategoricalCrossentropy(),\n",
    "]\n",
    "optimizer_list = ['adam', 'sgd']\n",
    "learning_rate_list = [1e-3, 1e-4]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "for num_filters in num_filters_list:\n",
    "    for kernel_size in kernel_size_list:\n",
    "        for dense_units in dense_units_list:\n",
    "            for dropout_rate in dropout_rate_list:\n",
    "                for regularizer in regularizer_list:\n",
    "                    for loss in loss_list:\n",
    "                        for optimizer in optimizer_list:\n",
    "                            for learning_rate in learning_rate_list:\n",
    "                                def model_init_fn():\n",
    "                                    return CustomConvNet(num_filters, kernel_size, dense_units, dropout_rate, regularizer)\n",
    "    \n",
    "                                def optimizer_init_fn():\n",
    "                                    if optimizer == 'adam':\n",
    "                                        return tf.keras.optimizers.Adam(learning_rate)\n",
    "                                    elif optimizer == 'sgd':\n",
    "                                        return tf.keras.optimizers.SGD(learning_rate)\n",
    "                                    elif optimizer == 'rmsprop':\n",
    "                                        return tf.keras.optimizers.RMSprop(learning_rate)\n",
    "    \n",
    "                                test_acc = train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True, print_every=16, loss_fn=loss)\n",
    "\n",
    "                                current_params = {'num_filters': num_filters, 'kernel_size': kernel_size, 'dense_units': dense_units, 'dropout_rate': dropout_rate, 'regularizer': regularizer, 'loss_fn': loss.name, 'optimizer': optimizer, 'learning_rate': learning_rate, 'test_acc': test_acc}\n",
    "\n",
    "                                results.append(current_params)\n",
    "    \n",
    "                                if test_acc > best_accuracy:\n",
    "                                    best_accuracy = test_acc\n",
    "                                    best_params = current_params\n",
    "\n",
    "\n",
    "print(f\"\\nBest accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Best parameters:\", best_params)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(64,), output.shape=(64, 8, 8, 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[119], line 43\u001B[0m\n\u001B[1;32m     40\u001B[0m     learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-3\u001B[39m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate) \n\u001B[0;32m---> 43\u001B[0m \u001B[43mtrain_part34\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_init_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_init_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[110], line 43\u001B[0m, in \u001B[0;36mtrain_part34\u001B[0;34m(model_init_fn, optimizer_init_fn, num_epochs, is_training, print_every)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[1;32m     40\u001B[0m     \n\u001B[1;32m     41\u001B[0m     \u001B[38;5;66;03m# Use the model function to build the forward pass.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m     scores \u001B[38;5;241m=\u001B[39m model(x_np, training\u001B[38;5;241m=\u001B[39mis_training)\n\u001B[0;32m---> 43\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_np\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     gradients \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n\u001B[1;32m     46\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mapply_gradients(\u001B[38;5;28mzip\u001B[39m(gradients, model\u001B[38;5;241m.\u001B[39mtrainable_variables))\n",
      "File \u001B[0;32m~/Documents/У(ч)ёба/DeepDarkLearningLabs/venv/lib/python3.11/site-packages/keras/src/losses/loss.py:43\u001B[0m, in \u001B[0;36mLoss.__call__\u001B[0;34m(self, y_true, y_pred, sample_weight)\u001B[0m\n\u001B[1;32m     36\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype), y_pred\n\u001B[1;32m     38\u001B[0m )\n\u001B[1;32m     39\u001B[0m y_true \u001B[38;5;241m=\u001B[39m tree\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(x, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype), y_true\n\u001B[1;32m     41\u001B[0m )\n\u001B[0;32m---> 43\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m out_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(losses, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_keras_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m in_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m out_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/Documents/У(ч)ёба/DeepDarkLearningLabs/venv/lib/python3.11/site-packages/keras/src/losses/losses.py:22\u001B[0m, in \u001B[0;36mLossFunctionWrapper.call\u001B[0;34m(self, y_true, y_pred)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, y_true, y_pred):\n\u001B[1;32m     21\u001B[0m     y_true, y_pred \u001B[38;5;241m=\u001B[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/У(ч)ёба/DeepDarkLearningLabs/venv/lib/python3.11/site-packages/keras/src/losses/losses.py:1722\u001B[0m, in \u001B[0;36msparse_categorical_crossentropy\u001B[0;34m(y_true, y_pred, from_logits, ignore_class, axis)\u001B[0m\n\u001B[1;32m   1717\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m y_true \u001B[38;5;241m*\u001B[39m ops\u001B[38;5;241m.\u001B[39mcast(valid_mask, y_true\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   1718\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m y_pred \u001B[38;5;241m*\u001B[39m ops\u001B[38;5;241m.\u001B[39mcast(\n\u001B[1;32m   1719\u001B[0m         ops\u001B[38;5;241m.\u001B[39mexpand_dims(valid_mask, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), y_pred\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m   1720\u001B[0m     )\n\u001B[0;32m-> 1722\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse_categorical_crossentropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1723\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1724\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1725\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfrom_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_logits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1726\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1727\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1729\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_class \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1730\u001B[0m     valid_mask \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mreshape(valid_mask, res_shape)\n",
      "File \u001B[0;32m~/Documents/У(ч)ёба/DeepDarkLearningLabs/venv/lib/python3.11/site-packages/keras/src/ops/nn.py:1567\u001B[0m, in \u001B[0;36msparse_categorical_crossentropy\u001B[0;34m(target, output, from_logits, axis)\u001B[0m\n\u001B[1;32m   1563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m any_symbolic_tensors((target, output)):\n\u001B[1;32m   1564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SparseCategoricalCrossentropy(\n\u001B[1;32m   1565\u001B[0m         from_logits\u001B[38;5;241m=\u001B[39mfrom_logits, axis\u001B[38;5;241m=\u001B[39maxis\n\u001B[1;32m   1566\u001B[0m     )\u001B[38;5;241m.\u001B[39msymbolic_call(target, output)\n\u001B[0;32m-> 1567\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse_categorical_crossentropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\n\u001B[1;32m   1569\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/У(ч)ёба/DeepDarkLearningLabs/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:619\u001B[0m, in \u001B[0;36msparse_categorical_crossentropy\u001B[0;34m(target, output, from_logits, axis)\u001B[0m\n\u001B[1;32m    613\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    614\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument `output` must be at least rank 1. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    615\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    616\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    617\u001B[0m     )\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(output\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]):\n\u001B[0;32m--> 619\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    620\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument `output` must have rank (ndim) `target.ndim - 1`. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    621\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    622\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, output.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    623\u001B[0m     )\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e1, e2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape, output\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]):\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e1 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e2 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e1 \u001B[38;5;241m!=\u001B[39m e2:\n",
      "\u001B[0;31mValueError\u001B[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(64,), output.shape=(64, 8, 8, 1)"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
