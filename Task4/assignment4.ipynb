{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.712303Z",
     "start_time": "2024-05-04T21:49:50.708253Z"
    }
   },
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "image_h = 8\n",
    "image_w = 8\n",
    "image_size = image_h * image_w\n",
    "print_every = 100\n",
    "\n",
    "\n",
    "device = '/CPU:0'"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.832319Z",
     "start_time": "2024-05-04T21:49:50.820254Z"
    }
   },
   "source": [
    "def load_dataset(test_proportion=0.2, val_proportion=0.2, flatten=True):\n",
    "    digits = load_digits()\n",
    "    digits_data = digits.data if flatten else digits.data.reshape(digits.data.shape[0], 8, 8, 1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(digits_data, digits.target, test_size=val_proportion, random_state=1337)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_proportion / (1 - val_proportion), random_state=1337)\n",
    "\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=False)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (1077, 8, 8, 1)\n",
      "Train labels shape:  (1077,) int64\n",
      "Validation data shape:  (360, 8, 8, 1)\n",
      "Validation labels shape:  (360,)\n",
      "Test data shape:  (360, 8, 8, 1)\n",
      "Test labels shape:  (360,)\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.865977Z",
     "start_time": "2024-05-04T21:49:50.862255Z"
    }
   },
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.882175Z",
     "start_time": "2024-05-04T21:49:50.879597Z"
    }
   },
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 8, 8, 1) (64,)\n",
      "1 (64, 8, 8, 1) (64,)\n",
      "2 (64, 8, 8, 1) (64,)\n",
      "3 (64, 8, 8, 1) (64,)\n",
      "4 (64, 8, 8, 1) (64,)\n",
      "5 (64, 8, 8, 1) (64,)\n",
      "6 (64, 8, 8, 1) (64,)\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.915020Z",
     "start_time": "2024-05-04T21:49:50.892084Z"
    }
   },
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU \n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU \n",
    "5. Полносвязный слой \n",
    "6. Функция активации Softmax \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.920179Z",
     "start_time": "2024-05-04T21:49:50.915962Z"
    }
   },
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), activation='relu', padding='same',\n",
    "                                            kernel_initializer=initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), activation='relu', padding='same',\n",
    "                                            kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu',\n",
    "                                         kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                         kernel_initializer=initializer)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        scores = self.fc2(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.987297Z",
     "start_time": "2024-05-04T21:49:50.948221Z"
    }
   },
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 1, 8, 8))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:50.993150Z",
     "start_time": "2024-05-04T21:49:50.988301Z"
    }
   },
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False, print_every = 1):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "\n",
    "        \n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            # train_loss.reset_states()\n",
    "            # train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        # val_loss.reset_states()\n",
    "                        # val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:51.688656Z",
     "start_time": "2024-05-04T21:49:51.005264Z"
    }
   },
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 10.919036865234375, Accuracy: 12.5, Val Loss: 31.35205078125, Val Accuracy: 32.22222137451172\n",
      "Iteration 1, Epoch 1, Loss: 21.587610244750977, Accuracy: 19.53125, Val Loss: 33.209129333496094, Val Accuracy: 37.08333206176758\n",
      "Iteration 2, Epoch 1, Loss: 27.471481323242188, Accuracy: 24.479167938232422, Val Loss: 31.56679916381836, Val Accuracy: 42.87036895751953\n",
      "Iteration 3, Epoch 1, Loss: 26.796615600585938, Accuracy: 34.375, Val Loss: 27.134429931640625, Val Accuracy: 47.5\n",
      "Iteration 4, Epoch 1, Loss: 24.190563201904297, Accuracy: 39.6875, Val Loss: 22.95987892150879, Val Accuracy: 52.33333206176758\n",
      "Iteration 5, Epoch 1, Loss: 20.979745864868164, Accuracy: 46.875, Val Loss: 19.635597229003906, Val Accuracy: 57.1296272277832\n",
      "Iteration 6, Epoch 1, Loss: 18.693925857543945, Accuracy: 52.00892639160156, Val Loss: 17.074548721313477, Val Accuracy: 61.74603271484375\n",
      "Iteration 7, Epoch 1, Loss: 16.5585994720459, Accuracy: 56.0546875, Val Loss: 15.083680152893066, Val Accuracy: 65.38194274902344\n",
      "Iteration 8, Epoch 1, Loss: 14.881159782409668, Accuracy: 59.54861068725586, Val Loss: 13.570329666137695, Val Accuracy: 68.02468872070312\n",
      "Iteration 9, Epoch 1, Loss: 13.712445259094238, Accuracy: 62.5, Val Loss: 12.351313591003418, Val Accuracy: 70.11111450195312\n",
      "Iteration 10, Epoch 1, Loss: 12.611031532287598, Accuracy: 64.9147720336914, Val Loss: 11.470657348632812, Val Accuracy: 71.16161346435547\n",
      "Iteration 11, Epoch 1, Loss: 11.704541206359863, Accuracy: 66.66667175292969, Val Loss: 10.606492042541504, Val Accuracy: 72.70833587646484\n",
      "Iteration 12, Epoch 1, Loss: 11.129697799682617, Accuracy: 67.66827392578125, Val Loss: 9.970918655395508, Val Accuracy: 73.65384674072266\n",
      "Iteration 13, Epoch 1, Loss: 10.463964462280273, Accuracy: 68.86161041259766, Val Loss: 9.333039283752441, Val Accuracy: 74.8214340209961\n",
      "Iteration 14, Epoch 1, Loss: 9.932785034179688, Accuracy: 69.89583587646484, Val Loss: 8.775906562805176, Val Accuracy: 75.90740966796875\n",
      "Iteration 15, Epoch 1, Loss: 9.388019561767578, Accuracy: 70.80078125, Val Loss: 8.309295654296875, Val Accuracy: 76.7361068725586\n",
      "Iteration 16, Epoch 1, Loss: 8.917167663574219, Accuracy: 71.77344512939453, Val Loss: 7.864323139190674, Val Accuracy: 77.71241760253906\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:52.645254Z",
     "start_time": "2024-05-04T21:49:51.689757Z"
    }
   },
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, print_every=1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 6.715267658233643, Accuracy: 12.5, Val Loss: 6.063634872436523, Val Accuracy: 22.77777862548828\n",
      "Iteration 1, Epoch 1, Loss: 6.787145614624023, Accuracy: 13.28125, Val Loss: 5.429378509521484, Val Accuracy: 27.08333396911621\n",
      "Iteration 2, Epoch 1, Loss: 6.187694549560547, Accuracy: 18.229167938232422, Val Loss: 4.6316328048706055, Val Accuracy: 31.94444465637207\n",
      "Iteration 3, Epoch 1, Loss: 5.347072601318359, Accuracy: 26.171875, Val Loss: 4.050225734710693, Val Accuracy: 35.48611068725586\n",
      "Iteration 4, Epoch 1, Loss: 4.67435884475708, Accuracy: 30.937498092651367, Val Loss: 3.5968668460845947, Val Accuracy: 38.77777862548828\n",
      "Iteration 5, Epoch 1, Loss: 4.26380729675293, Accuracy: 33.854164123535156, Val Loss: 3.208817958831787, Val Accuracy: 42.5\n",
      "Iteration 6, Epoch 1, Loss: 3.8333230018615723, Accuracy: 39.28571319580078, Val Loss: 2.899141550064087, Val Accuracy: 45.55555725097656\n",
      "Iteration 7, Epoch 1, Loss: 3.500703811645508, Accuracy: 42.578125, Val Loss: 2.6477761268615723, Val Accuracy: 48.71527862548828\n",
      "Iteration 8, Epoch 1, Loss: 3.2186949253082275, Accuracy: 45.48611068725586, Val Loss: 2.4380786418914795, Val Accuracy: 51.666664123535156\n",
      "Iteration 9, Epoch 1, Loss: 2.968355655670166, Accuracy: 48.59375, Val Loss: 2.2623367309570312, Val Accuracy: 54.333335876464844\n",
      "Iteration 10, Epoch 1, Loss: 2.763967752456665, Accuracy: 51.70454406738281, Val Loss: 2.1127750873565674, Val Accuracy: 56.84343719482422\n",
      "Iteration 11, Epoch 1, Loss: 2.5781776905059814, Accuracy: 54.16666793823242, Val Loss: 1.983620524406433, Val Accuracy: 59.166664123535156\n",
      "Iteration 12, Epoch 1, Loss: 2.4278719425201416, Accuracy: 56.009613037109375, Val Loss: 1.8708761930465698, Val Accuracy: 61.21794509887695\n",
      "Iteration 13, Epoch 1, Loss: 2.2902634143829346, Accuracy: 58.482139587402344, Val Loss: 1.7715530395507812, Val Accuracy: 63.03571319580078\n",
      "Iteration 14, Epoch 1, Loss: 2.1713852882385254, Accuracy: 60.20833206176758, Val Loss: 1.683414340019226, Val Accuracy: 64.72222137451172\n",
      "Iteration 15, Epoch 1, Loss: 2.0624067783355713, Accuracy: 61.81640625, Val Loss: 1.6039162874221802, Val Accuracy: 66.2326431274414\n",
      "Iteration 16, Epoch 1, Loss: 1.9607203006744385, Accuracy: 63.32404708862305, Val Loss: 1.5319018363952637, Val Accuracy: 67.6143798828125\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:53.210853Z",
     "start_time": "2024-05-04T21:49:52.646202Z"
    }
   },
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (8, 8, 1)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 8.354377746582031, Accuracy: 21.875, Val Loss: 10.78812313079834, Val Accuracy: 50.55555725097656\n",
      "Iteration 1, Epoch 1, Loss: 9.014751434326172, Accuracy: 37.5, Val Loss: 11.083678245544434, Val Accuracy: 57.08333206176758\n",
      "Iteration 2, Epoch 1, Loss: 8.383711814880371, Accuracy: 48.958335876464844, Val Loss: 9.200718879699707, Val Accuracy: 58.611114501953125\n",
      "Iteration 3, Epoch 1, Loss: 7.09971809387207, Accuracy: 53.515625, Val Loss: 8.533074378967285, Val Accuracy: 61.94444274902344\n",
      "Iteration 4, Epoch 1, Loss: 6.8924126625061035, Accuracy: 56.875003814697266, Val Loss: 8.50089168548584, Val Accuracy: 62.722225189208984\n",
      "Iteration 5, Epoch 1, Loss: 6.791250705718994, Accuracy: 58.07291793823242, Val Loss: 8.501493453979492, Val Accuracy: 63.65740966796875\n",
      "Iteration 6, Epoch 1, Loss: 6.929023265838623, Accuracy: 59.15178680419922, Val Loss: 7.803183555603027, Val Accuracy: 65.75396728515625\n",
      "Iteration 7, Epoch 1, Loss: 6.859646797180176, Accuracy: 60.15625, Val Loss: 7.1927103996276855, Val Accuracy: 67.63888549804688\n",
      "Iteration 8, Epoch 1, Loss: 6.550956726074219, Accuracy: 61.63194274902344, Val Loss: 6.574892997741699, Val Accuracy: 69.53704071044922\n",
      "Iteration 9, Epoch 1, Loss: 6.2261643409729, Accuracy: 64.0625, Val Loss: 6.019697666168213, Val Accuracy: 71.77777862548828\n",
      "Iteration 10, Epoch 1, Loss: 5.716903209686279, Accuracy: 66.4772720336914, Val Loss: 5.583284378051758, Val Accuracy: 73.38383483886719\n",
      "Iteration 11, Epoch 1, Loss: 5.355373382568359, Accuracy: 68.22917175292969, Val Loss: 5.266744613647461, Val Accuracy: 74.60648345947266\n",
      "Iteration 12, Epoch 1, Loss: 5.469635486602783, Accuracy: 68.62980651855469, Val Loss: 5.033541202545166, Val Accuracy: 75.0\n",
      "Iteration 13, Epoch 1, Loss: 5.102203845977783, Accuracy: 70.08928680419922, Val Loss: 4.7298102378845215, Val Accuracy: 76.15079498291016\n",
      "Iteration 14, Epoch 1, Loss: 4.8436713218688965, Accuracy: 71.5625, Val Loss: 4.464822292327881, Val Accuracy: 77.09259033203125\n",
      "Iteration 15, Epoch 1, Loss: 4.599599838256836, Accuracy: 72.75390625, Val Loss: 4.251720905303955, Val Accuracy: 77.93402862548828\n",
      "Iteration 16, Epoch 1, Loss: 4.401580810546875, Accuracy: 73.90901184082031, Val Loss: 4.050291538238525, Val Accuracy: 78.79084777832031\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:53.599474Z",
     "start_time": "2024-05-04T21:49:53.211968Z"
    }
   },
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m17/17\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 15.0409 - sparse_categorical_accuracy: 0.5379 - val_loss: 0.6492 - val_sparse_categorical_accuracy: 0.9361\n",
      "\u001B[1m12/12\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 824us/step - loss: 0.5338 - sparse_categorical_accuracy: 0.9092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.763836681842804, 0.9027777910232544]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:53.625326Z",
     "start_time": "2024-05-04T21:49:53.600243Z"
    }
   },
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    pass\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    pass\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[101], line 32\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;66;03m# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001B[39;00m\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;66;03m############################################################################\u001B[39;00m\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;66;03m#                           END OF YOUR CODE                               #\u001B[39;00m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;66;03m############################################################################\u001B[39;00m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m optimizer\n\u001B[0;32m---> 32\u001B[0m \u001B[43mtrain_part34\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_init_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_init_fn\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[96], line 42\u001B[0m, in \u001B[0;36mtrain_part34\u001B[0;34m(model_init_fn, optimizer_init_fn, num_epochs, is_training, print_every)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x_np, y_np \u001B[38;5;129;01min\u001B[39;00m train_dset:\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mGradientTape() \u001B[38;5;28;01mas\u001B[39;00m tape:\n\u001B[1;32m     40\u001B[0m         \n\u001B[1;32m     41\u001B[0m         \u001B[38;5;66;03m# Use the model function to build the forward pass.\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m         scores \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_np\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_training\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m         loss \u001B[38;5;241m=\u001B[39m loss_fn(y_np, scores)\n\u001B[1;32m     45\u001B[0m         gradients \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mgradient(loss, model\u001B[38;5;241m.\u001B[39mtrainable_variables)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T21:49:53.626181Z",
     "start_time": "2024-05-04T21:49:53.626112Z"
    }
   },
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
    "\n",
    "Ниже представлен пример для полносвязной сети. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "input_shape = (8, 8, 1)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        pass\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        pass\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 700\n",
    "num_epochs = 10\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
